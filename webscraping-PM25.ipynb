{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping Pollution Data from Website\n",
    "\n",
    "\n",
    "Reference\n",
    "1. http://berkeleyearth.lbl.gov/air-quality/maps/cities/Thailand/\n",
    "2. https://automatetheboringstuff.com/chapter11/ \n",
    "3. http://www.aqmthai.com/public_report.php\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download PM2.5  data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\Benny\\fastai\\old')\n",
    "from pathlib import Path\n",
    "from fastai.imports import *\n",
    "import requests\n",
    "import wget\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://berkeleyearth.lbl.gov/air-quality/maps/cities/Thailand/'\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all provinces in this database\n",
    "provinces = soup.find_all(href=re.compile('/'))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkk = provinces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangkok/',\n",
       " 'Nonthaburi/',\n",
       " 'Samut_Prakan/',\n",
       " 'Samut_Sakhon/',\n",
       " 'Pathum_Thani/',\n",
       " 'Nakhon_Pathom/',\n",
       " 'Phra_Nakhon_Si_Ayutthaya/',\n",
       " 'Ratchaburi/']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bulid a list of provinces to download the data \n",
    "to_grab = []\n",
    "to_grab.append(bkk['href'])\n",
    "nei_url = url+to_grab[0].replace('/','')+'.neighbors.json'\n",
    "bkk_j = requests.get(nei_url).json()\n",
    "nei = [prov[1]+'/' for prov in bkk_j if prov[0]=='Thailand']\n",
    "\n",
    "# some provinces in the list are not the province of interest's neighbors \n",
    "to_grab = to_grab+nei[:7]\n",
    "to_grab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"Bangkok/\">Bangkok/</a>]\n",
      "[<a href=\"Nonthaburi/\">Nonthaburi/</a>]\n",
      "[<a href=\"Samut_Prakan/\">Samut_Prakan/</a>]\n",
      "[<a href=\"Samut_Sakhon/\">Samut_Sakhon/</a>]\n",
      "[<a href=\"Pathum_Thani/\">Pathum_Thani/</a>]\n",
      "[<a href=\"Nakhon_Pathom/\">Nakhon_Pathom/</a>]\n",
      "[<a href=\"Phra_Nakhon_Si_Ayutthaya/\">Phra_Nakhon_Si_Ayutthaya/</a>]\n",
      "[<a href=\"Ratchaburi/\">Ratchaburi/</a>]\n"
     ]
    }
   ],
   "source": [
    "for folder in to_grab: \n",
    "    link = soup.find_all(href = re.compile(folder))\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('data').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_txt(folder):\n",
    "    grab_url = url+folder\n",
    "    prov_r = requests.get(grab_url)\n",
    "    prov_s = BeautifulSoup(prov_r.text)\n",
    "    for tag in prov_s.find_all(href=re.compile('.txt')):\n",
    "        data_url = grab_url+tag['href']\n",
    "        name = 'data/'+ tag['href']\n",
    "        wget.download(data_url,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [............................................................................] 576938 / 576938"
     ]
    }
   ],
   "source": [
    "for folder in to_grab:\n",
    "    download_txt(folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
